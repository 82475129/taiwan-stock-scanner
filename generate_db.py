import json
import requests
from bs4 import BeautifulSoup
import time
from tqdm import tqdm

def generate_electronic_stocks_db():
    print("ğŸš€ åµæ¸¬åˆ° Yahoo ç¶²é æ”¹ç‰ˆï¼Œå•Ÿå‹•æ·±åº¦çˆ¬å–æ¨¡å¼...")
    
    # é€™æ˜¯é›»å­ç”¢æ¥­ç´°åˆ†é é¢çš„æ ¹ç¶²å€
    base_url = "https://tw.stock.yahoo.com"
    # ç›´æ¥é–å®šé›»å­ç”¢æ¥­çš„é¡åˆ¥é é¢ (åŒ…å«ä½ çµ¦çš„ HTML è£¡çš„é‚£äº›åˆ†é¡)
    start_url = "https://tw.stock.yahoo.com/class" 
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    }
    
    db_result = {}
    
    # 1. é€™è£¡æ‰‹å‹•åˆ—å‡ºä½ æä¾›çš„ HTML ä¸­æœ€é‡è¦çš„ç´°åˆ†åˆ†é¡é€£çµ (ç¯„ä¾‹)
    # å¯¦éš›ä¸Šæˆ‘å€‘æœƒå‹•æ…‹æŠ“å–ï¼Œä½†ç‚ºäº†ä¿éšªï¼Œæˆ‘å€‘ç›´æ¥å®šç¾©é›»å­æ¥­å¸¸ç”¨çš„ ID
    # æ ¹æ“šæ–°ç‰ˆ Yahooï¼Œæˆ‘å€‘ç›´æ¥æŠ“å–ã€Œé›»å­ç”¢æ¥­ã€ä¸‹çš„æ‰€æœ‰ç´°åˆ†é¡
    categories = [
        "è¨­å‚™æˆ–å» å‹™å·¥ç¨‹", "é›»å­è¨­å‚™è²·è³£", "å…¶ä»–é›¶çµ„ä»¶", "PC/NB/å¹³æ¿", "çµ„è£ä»£å·¥",
        "ICç”Ÿç”¢è£½é€ ", "å…¶ä»–å…‰é›»", "æ¶ˆè²»é›»å­æˆ–é›»å™¨", "æ‰‹æ©Ÿç›¸é—œ", "è»Ÿé«”è¨­è¨ˆ",
        "ç³»çµ±æ•´åˆ", "ç¶²é€šè¨­å‚™çµ„ä»¶", "ICè¨­è¨ˆæœå‹™", "LED", "å¤ªé™½èƒ½", "PCB",
        "æ©Ÿæ®¼", "é¢æ¿æ¥­", "é›»æ± æˆ–é›»æº", "å…‰å­¸å…ƒä»¶æˆ–çµ„è£", "è¢«å‹•å…ƒä»¶", "å·¥æ¥­é›»è…¦"
    ]
    
    # ç‚ºäº†ç°¡åŒ–ï¼Œæˆ‘å€‘ç›´æ¥æŠ“å–ã€Œä¸Šå¸‚é›»å­ã€èˆ‡ã€Œä¸Šæ«ƒé›»å­ã€çš„ç¸½è¡¨ï¼Œé€™æœ€ç©©
    main_sectors = [
        {"ex": "TAI", "name": "ä¸Šå¸‚é›»å­", "url": "https://tw.stock.yahoo.com/class-quote?sectorId=46&exchange=TAI"}, # å‡è¨­çš„ IDï¼Œæˆ‘å€‘æœƒç”¨é€šç”¨é¸å–å™¨
    ]

    # --- ä¿®æ­£å¾Œçš„è¬ç”¨æŠ“å–é‚è¼¯ ---
    # æˆ‘å€‘æ”¹ç”¨ Yahoo çš„ã€Œæ‰€æœ‰ç”¢æ¥­ã€æ¸…å–®ä¾†æ’ˆé›»å­è‚¡
    print("æ­£åœ¨æŠ“å–å…¨å°é›»å­æ¨™çš„...")
    
    # é›»å­è‚¡çš„é—œéµå­—
    target_keywords = ["é›»å­", "åŠå°é«”", "é›»è…¦", "å…‰é›»", "é€šä¿¡", "è³‡è¨Š", "ç¶²è·¯", "IC", "PCB"]
    
    # é€™è£¡æˆ‘å€‘ç”¨ä¸€å€‹æ›´æš´åŠ›ä½†ä¹Ÿæ›´ç©©çš„æ–¹æ³•ï¼šç›´æ¥æŠ“å– Yahoo æ‰€æœ‰çš„é›»å­åˆ†é¡ ID
    # ä¸Šå¸‚é›»å­é¡ ID ç¯„åœé€šå¸¸åœ¨ 40~47ï¼Œä¸Šæ«ƒåœ¨ 153~160
    sector_ids = list(range(40, 48)) + list(range(153, 161))
    
    pbar = tqdm(sector_ids, desc="æƒæé›»å­åˆ†é¡")

    for sid in pbar:
        exchange = "TAI" if sid < 100 else "TWO"
        url = f"https://tw.stock.yahoo.com/class-quote?sectorId={sid}&exchange={exchange}"
        
        try:
            resp = requests.get(url, headers=headers, timeout=10)
            soup = BeautifulSoup(resp.text, 'html.parser')
            
            # é—œéµä¿®æ­£ï¼šæ–°ç‰ˆ Yahoo çš„è‚¡ç¥¨åç¨±å’Œä»£è™ŸåŒ…åœ¨ 'div' æˆ–æ˜¯ 'a' æ¨™ç±¤è£¡
            # æˆ‘å€‘ç›´æ¥æ‰¾åŒ…å«è‚¡ç¥¨ä»£è™Ÿæ•¸å­—çš„æ–‡å­—
            rows = soup.select('div[class*="table-row"]')
            
            for row in rows:
                # æŠ“å–ä»£è™Ÿ (é€šå¸¸æ˜¯ 4 ä½æ•¸å­—)
                code_el = row.select_one('span[class*="C(#7c7e80)"]')
                # æŠ“å–åç¨±
                name_el = row.select_one('div[class*="Lh(20px)"]')
                
                if code_el and name_el:
                    code = code_el.get_text(strip=True)
                    name = name_el.get_text(strip=True)
                    if code.isdigit() and len(code) >= 4:
                        suffix = ".TW" if exchange == "TAI" else ".TWO"
                        db_result[f"{code}{suffix}"] = name
            
            time.sleep(0.5)
        except:
            continue

    # å„²å­˜
    with open("taiwan_electronic_stocks.json", 'w', encoding='utf-8') as f:
        json.dump(db_result, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… æˆåŠŸï¼å…±æŠ“å– {len(db_result)} æª”é›»å­è‚¡ã€‚")

if __name__ == "__main__":
    generate_electronic_stocks_db()
