import json
import requests
from bs4 import BeautifulSoup
from tqdm import tqdm
import time

def get_target_configs():
    """å®šç¾©è¦çˆ¬å–çš„åˆ†é¡ï¼šåŒ…å«ç”¢æ¥­ ID èˆ‡ ç‰¹æ®Šé›†åœ˜è‚¡ç¶²å€"""
    configs = []
    # 1. é›»å­ç”¢æ¥­åˆ†é¡ (ä¸Šå¸‚ 40~47, ä¸Šæ«ƒ 153~160)
    sids = list(range(40, 48)) + list(range(153, 161))
    for sid in sids:
        ex = "TAI" if sid < 100 else "TWO"
        configs.append({"name": f"Sector_{sid}", "url": f"https://tw.stock.yahoo.com/class-quote?sectorId={sid}&exchange={ex}"})
    
    # 2. åŠ å…¥ä½ æåˆ°çš„é›†åœ˜è‚¡ (ä¸­å¤©ç”ŸæŠ€)
    configs.append({
        "name": "ä¸­å¤©é›†åœ˜è‚¡",
        "url": "https://tw.stock.yahoo.com/class-quote?category=%E4%B8%AD%E5%A4%A9%E7%94%9F%E6%8A%80&categoryLabel=%E9%9B%86%E5%9C%98%E8%82%A1"
    })
    return configs

def crawl_yahoo_class(config):
    """æ ¸å¿ƒçˆ¬èŸ²ï¼šæŠ“å– HTML åˆ—è¡¨ä¸­çš„æ‰€æœ‰è‚¡ç¥¨èˆ‡è©³ç´°æ•¸å€¼"""
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'}
    results = {}
    try:
        resp = requests.get(config['url'], headers=headers, timeout=15)
        if resp.status_code != 200: return {}
        
        soup = BeautifulSoup(resp.text, 'html.parser')
        rows = soup.select('li.List\(n\)') # å®šä½æ¯ä¸€åˆ—è‚¡ç¥¨
        
        for row in rows:
            # æŠ“å–åç¨±èˆ‡ä»£ç¢¼
            name_div = row.select_one('div.Lh\(20px\)')
            code_span = row.select_one('span.Fz\(14px\)')
            if not name_div or not code_span: continue
            
            symbol = code_span.text.strip() # å¦‚ 2330.TW
            
            # æŠ“å–æ‰€æœ‰æ•¸å€¼æ¬„ä½ (ä¾åºç‚ºï¼šæˆäº¤ã€æ¼²è·Œã€æ¼²è·Œå¹…ã€é–‹ç›¤ã€æ˜¨æ”¶ã€æœ€é«˜ã€æœ€ä½ã€æˆäº¤é‡)
            cols = row.select('div.Ta\(end\)')
            if len(cols) >= 8:
                results[symbol] = {
                    "name": name_div.text.strip(),
                    "price": cols[0].text.strip(),
                    "change_p": cols[2].text.strip(),
                    "open": cols[3].text.strip(),
                    "high": cols[5].text.strip(),
                    "low": cols[6].text.strip(),
                    "vol": cols[7].text.strip().replace(',', '') # å»é™¤åƒåˆ†ä½
                }
        return results
    except Exception as e:
        print(f"Error in {config['name']}: {e}")
        return {}

def main():
    print("ğŸš€ å•Ÿå‹•å…¨é‡è³‡æ–™æŠ“å–...")
    all_stocks = {}
    configs = get_target_configs()
    
    for conf in tqdm(configs):
        data = crawl_yahoo_class(conf)
        all_stocks.update(data)
        time.sleep(0.5)
    
    if all_stocks:
        with open("taiwan_electronic_stocks.json", "w", encoding="utf-8") as f:
            json.dump(all_stocks, f, ensure_ascii=False, indent=2)
        print(f"ğŸ‰ å®Œæˆï¼å…±å­˜å„² {len(all_stocks)} æª”è‚¡ç¥¨è©³ç´°è³‡æ–™")

if __name__ == "__main__":
    main()
